# Bandit-Simulator

Multi-Armed Bandit Simulator with implementation of core algorithms.

---

## ðŸ“‹ Overview

This repository implements a framework for simulating and comparing **multi-armed bandit** algorithms. Currently, the Îµ-Greedy policy is implemented, with a bandit environment that uses (for now) a Gaussian (normal) reward distribution.  

Over time the aim is to add more algorithms (UCB, Thompson Sampling, etc.) and more bandit types.

---

